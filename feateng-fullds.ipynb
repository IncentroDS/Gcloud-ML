{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Feature Engineering </h1>\n",
    "\n",
    "This notebook runs preprocessing on the full dataset.  It is the same as feateng.ipynb except for the change to do the whole thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11.0rc0\n",
      "gs://cloud-ml/sdk/cloudml-0.1.6-alpha.dataflow.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import google.cloud.ml as ml\n",
    "import tensorflow as tf\n",
    "print tf.__version__\n",
    "print ml.sdk_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Specifying query to pull the data </h1>\n",
    "\n",
    "Same as feateng.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT\n",
      "  DAYOFWEEK(pickup_datetime)*1.0 AS dayofweek,\n",
      "  HOUR(pickup_datetime)*1.0 AS hourofday,\n",
      "  pickup_longitude, pickup_latitude, \n",
      "  dropoff_longitude, dropoff_latitude,\n",
      "  passenger_count*1.0 AS passenger_count,\n",
      "  (tolls_amount + fare_amount) as fare_amount\n",
      "FROM\n",
      "  [nyc-tlc:yellow.trips]\n",
      "WHERE\n",
      "    trip_distance > 0\n",
      "    AND fare_amount >= 2.5\n",
      "    AND pickup_longitude > -78\n",
      "    AND pickup_longitude < -70\n",
      "    AND dropoff_longitude > -78\n",
      "    AND dropoff_longitude < -70\n",
      "    AND pickup_latitude > 37\n",
      "    AND pickup_latitude < 45\n",
      "    AND dropoff_latitude > 37\n",
      "    AND dropoff_latitude < 45\n",
      "    AND passenger_count > 0 \n",
      "   AND ABS(HASH(pickup_datetime)) % 100000 == 2\n"
     ]
    }
   ],
   "source": [
    "def create_query(phase, EVERY_N):\n",
    "  \"\"\"\n",
    "  phase: 1=train 2=valid\n",
    "  \"\"\"\n",
    "  base_query = \"\"\"\n",
    "SELECT\n",
    "  DAYOFWEEK(pickup_datetime)*1.0 AS dayofweek,\n",
    "  HOUR(pickup_datetime)*1.0 AS hourofday,\n",
    "  pickup_longitude, pickup_latitude, \n",
    "  dropoff_longitude, dropoff_latitude,\n",
    "  passenger_count*1.0 AS passenger_count,\n",
    "  (tolls_amount + fare_amount) as fare_amount\n",
    "FROM\n",
    "  [nyc-tlc:yellow.trips]\n",
    "WHERE\n",
    "    trip_distance > 0\n",
    "    AND fare_amount >= 2.5\n",
    "    AND pickup_longitude > -78\n",
    "    AND pickup_longitude < -70\n",
    "    AND dropoff_longitude > -78\n",
    "    AND dropoff_longitude < -70\n",
    "    AND pickup_latitude > 37\n",
    "    AND pickup_latitude < 45\n",
    "    AND dropoff_latitude > 37\n",
    "    AND dropoff_latitude < 45\n",
    "    AND passenger_count > 0 \n",
    "  \"\"\"\n",
    "\n",
    "  if EVERY_N == None:\n",
    "    if phase < 2:\n",
    "      # training\n",
    "      query = \"{0} AND ABS(HASH(pickup_datetime)) % 4 < 2\".format(base_query)\n",
    "    else:\n",
    "      query = \"{0} AND ABS(HASH(pickup_datetime)) % 4 == {1}\".format(base_query, phase)\n",
    "  else:\n",
    "      query = \"{0} AND ABS(HASH(pickup_datetime)) % {1} == {2}\".format(base_query, EVERY_N, phase)\n",
    "\n",
    "  \n",
    "    \n",
    "  return query\n",
    "    \n",
    "print create_query(2, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Preprocessing features using Cloud ML SDK </h2>\n",
    "\n",
    "We could discretize the lat-lon columns using the SDK, but we'll defer that to TensorFlow to enable it to be a hyper-parameter if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml/sdk/cloudml-0.1.6-alpha.dataflow.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import google.cloud.ml.features as features\n",
    "\n",
    "import google.cloud.ml as ml\n",
    "print ml.sdk_location\n",
    "\n",
    "class TaxifareFeatures(object):\n",
    "  csv_columns = ('dayofweek', 'hourofday', 'pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','passenger_count','fare_amount')\n",
    "  fare_amount = features.target('fare_amount').continuous()\n",
    "  pcount = features.numeric('passenger_count').scale()\n",
    "  plat = features.numeric('pickup_latitude').scale()\n",
    "  dlat = features.numeric('dropoff_latitude').scale()\n",
    "  plon = features.numeric('pickup_longitude').scale()\n",
    "  dlon = features.numeric('dropoff_longitude').scale()\n",
    "  dayofweek = features.numeric('dayofweek').identity()\n",
    "  hourofday = features.numeric('hourofday').identity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Preprocessing Dataflow job from BigQuery </h2>\n",
    "\n",
    "This code reads from BigQuery and runs the above preprocessing, saving the data on Google Cloud.  Make sure to change the BUCKET and PROJECt variable to be yours.\n",
    "\n",
    "If you are running on the Cloud, you should go to the GCP Console to look at the status of the job. If you are running locally, you'll get a Running bar and it will take up to 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://cloud-training-demos-ml/taxifare/taxi_preproc4a_full/tmp/preprocess-fulldataset-161010-211806.1476134287.220213/#1476134298753743...\n",
      "Removing gs://cloud-training-demos-ml/taxifare/taxi_preproc4a_full/tmp/preprocess-fulldataset-161010-211806.1476134287.220213/14057931811737539378/000000000000.json#1476134691580412...\n",
      "Removing gs://cloud-training-demos-ml/taxifare/taxi_preproc4a_full/tmp/preprocess-fulldataset-161010-211806.1476134287.220213/14057931811737539378/000000000001.json#1476134768474115...\n",
      "Removing gs://cloud-training-demos-ml/taxifare/taxi_preproc4a_full/tmp/preprocess-fulldataset-161010-211806.1476134287.220213/14057931811737539378/000000000002.json#1476134711295995...\n",
      "Removing gs://cloud-training-demos-ml/taxifare/taxi_preproc4a_full/tmp/preprocess-fulldataset-161010-211806.1476134287.220213/14057931811737539378/000000000003.json#1476134623452576...\n",
      "/ [1/13 objects]   7% Done                                                      \r",
      "/ [2/13 objects]  15% Done                                                      \r",
      "/ [3/13 objects]  23% Done                                                      \r",
      "/ [4/13 objects]  30% Done                                                      \r",
      "Removing gs://cloud-training-demos-ml/taxifare/taxi_preproc4a_full/tmp/preprocess-fulldataset-161010-211806.1476134287.220213/14057931811737539378/000000000004.json#1476134670450586...\n",
      "Removing gs://cloud-training-demos-ml/taxifare/taxi_preproc4a_full/tmp/preprocess-fulldataset-161010-211806.1476134287.220213/dax-tmp-2016-10-10_14_18_13-16498596400570076-S01-1-65aa82298c9f76a1/#1476134299158744...\n",
      "/ [5/13 objects]  38% Done                                                      \r",
      "Removing gs://cloud-training-demos-ml/taxifare/taxi_preproc4a_full/tmp/preprocess-fulldataset-161010-211806.1476134287.220213/dax-tmp-2016-10-10_14_18_13-16498596400570076-S11-1-4fc039470fc62991/#1476134299135579...\n",
      "Removing gs://cloud-training-demos-ml/taxifare/taxi_preproc4a_full/tmp/preprocess-fulldataset-161010-211806.1476134287.220213/dax-tmp-2016-10-10_14_18_13-16498596400570076-S43-1-fa43b2017fb73a2d/#1476134299324871...\n",
      "Removing gs://cloud-training-demos-ml/taxifare/taxi_preproc4a_full/tmp/preprocess-fulldataset-161010-211806.1476134287.220213/dax-tmp-2016-10-10_14_18_13-16498596400570076-S54-1-54c50042f2dfc7eb/#1476134299188588...\n",
      "/ [6/13 objects]  46% Done                                                      \r",
      "/ [7/13 objects]  53% Done                                                      \r",
      "/ [8/13 objects]  61% Done                                                      \r",
      "Removing gs://cloud-training-demos-ml/taxifare/taxi_preproc4a_full/tmp/staging/preprocess-fulldataset-161010-211806.1476134287.220213/cloudml-0.1.6-alpha.dataflow.tar.gz#1476134288937061...\n",
      "Removing gs://cloud-training-demos-ml/taxifare/taxi_preproc4a_full/tmp/staging/preprocess-fulldataset-161010-211806.1476134287.220213/dataflow_python_sdk.tar#1476134292756095...\n",
      "Removing gs://cloud-training-demos-ml/taxifare/taxi_preproc4a_full/tmp/staging/preprocess-fulldataset-161010-211806.1476134287.220213/extra_packages.txt#1476134289040099...\n",
      "/ [9/13 objects]  69% Done                                                      \r",
      "/ [10/13 objects]  76% Done                                                     \r",
      "/ [11/13 objects]  84% Done                                                     \r",
      "/ [12/13 objects]  92% Done                                                     \r",
      "/ [13/13 objects] 100% Done                                                     \r\n",
      "Operation completed over 13 objects.                                             \n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "BUCKET=cloud-training-demos-ml\n",
    "gsutil -m rm -r -f gs://$BUCKET/taxifare/taxi_preproc4a_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Direct usage of TextFileSink is deprecated. Please use 'textio.WriteToText()' instead of directly instantiating a TextFileSink object.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DataflowPipelineResult <Job\n",
       " id: u'2016-10-10_14_42_26-17147159759562253325'\n",
       " projectId: u'cloud-training-demos'\n",
       " steps: []\n",
       " tempFiles: []\n",
       " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)> at 0x7fb5dbb67cd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import apache_beam as beam\n",
    "import google.cloud.ml as ml\n",
    "import google.cloud.ml.dataflow.io.tfrecordio as tfrecordio\n",
    "import google.cloud.ml.io as io\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Change as needed\n",
    "BUCKET = 'cloud-training-demos-ml'\n",
    "PROJECT = 'cloud-training-demos'\n",
    "EVERY_N = None # Change this to None to preprocess full dataset\n",
    "\n",
    "# Direct runs locally; Dataflow runs on the Cloud.\n",
    "#RUNNER = 'DirectPipelineRunner'\n",
    "RUNNER = 'DataflowPipelineRunner'\n",
    "\n",
    "OUTPUT_DIR = 'gs://{0}/taxifare/taxi_preproc4a_full/'.format(BUCKET)\n",
    "options = {\n",
    "    'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "    'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "    'job_name': 'preprocess-fulldataset' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S'),\n",
    "    'project': PROJECT,\n",
    "    'extra_packages': [ml.sdk_location],\n",
    "    'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "    'maxNumWorkers': 100,\n",
    "    'no_save_main_session': True\n",
    "}\n",
    "opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "pipeline = beam.Pipeline(RUNNER, options=opts)\n",
    "\n",
    "# defines\n",
    "feature_set = TaxifareFeatures()\n",
    "train_query = create_query(1, EVERY_N)\n",
    "valid_query = create_query(2, EVERY_N)\n",
    "train = pipeline | 'read_train' >> beam.Read(beam.io.BigQuerySource(query=train_query))\n",
    "eval = pipeline | 'read_valid' >> beam.Read(beam.io.BigQuerySource(query=valid_query))\n",
    "\n",
    "(metadata, train_features, eval_features) = ((train, eval) |\n",
    "   'Preprocess' >> ml.Preprocess(feature_set))\n",
    "\n",
    "(metadata\n",
    "   | 'SaveMetadata'\n",
    "   >> io.SaveMetadata(os.path.join(OUTPUT_DIR, 'metadata.yaml')))\n",
    "(train_features\n",
    "   | 'WriteTraining'\n",
    "   >> io.SaveFeatures(os.path.join(OUTPUT_DIR, 'features_train')))\n",
    "(eval_features\n",
    "   | 'WriteEval'\n",
    "   >> io.SaveFeatures(os.path.join(OUTPUT_DIR, 'features_eval')))\n",
    "\n",
    "# run pipeline\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-training-demos-ml/taxifare/taxi_preproc4a_full/tmp/\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://cloud-training-demos-ml/taxifare/taxi_preproc4a_full/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2016 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
